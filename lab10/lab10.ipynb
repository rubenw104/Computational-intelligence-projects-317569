{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:49:41.065533600Z",
     "start_time": "2023-12-25T18:49:40.698539500Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice,random\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:07:41.328949500Z",
     "start_time": "2023-12-24T12:07:41.167858300Z"
    }
   },
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:07:41.591929200Z",
     "start_time": "2023-12-24T12:07:41.302118Z"
    }
   },
   "outputs": [],
   "source": [
    "MAGIC = [2, 7, 6, \n",
    "         9, 5, 1, \n",
    "         4, 3, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T15:03:01.454349200Z",
     "start_time": "2023-12-24T15:03:01.266291500Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_board(pos):\n",
    "    \"\"\"Nicely prints the board\"\"\"\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            i = r * 3 + c\n",
    "            if MAGIC[i] in pos.x:\n",
    "                print('X', end='|')\n",
    "            elif MAGIC[i] in pos.o:\n",
    "                print('O', end='|')\n",
    "            else:\n",
    "                print('.', end='|')\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:07:42.147546700Z",
     "start_time": "2023-12-24T12:07:41.889418400Z"
    }
   },
   "outputs": [],
   "source": [
    "def win(elements):\n",
    "    \"\"\"Checks is elements is winning\"\"\"\n",
    "    return any(sum(c) == 15 for c in combinations(elements, 3))\n",
    "\n",
    "def state_value(pos: State):\n",
    "    \"\"\"Evaluate state: +1 first player wins\"\"\"\n",
    "    if win(pos.x):\n",
    "        return 1\n",
    "    elif win(pos.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:07:42.449671300Z",
     "start_time": "2023-12-24T12:07:42.170599Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_game():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "        x = choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "        if win(state.x) or not available:\n",
    "            break\n",
    "\n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        if win(state.o):\n",
    "            break\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T12:09:38.125347400Z",
     "start_time": "2023-12-24T12:07:42.465535900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b4418c312e84462afd4e8060f467b77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_dictionary = defaultdict(float)\n",
    "hit_state = defaultdict(int)\n",
    "epsilon = 0.001\n",
    "\n",
    "for steps in tqdm(range(100_000)):\n",
    "    trajectory = random_game()\n",
    "    final_reward = state_value(trajectory[-1])\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        hit_state[hashable_state] += 1\n",
    "        value_dictionary[hashable_state] = value_dictionary[\n",
    "            hashable_state\n",
    "        ] + epsilon * (final_reward - value_dictionary[hashable_state])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def best_move(state:State):\n",
    "    \"\"\"Montecarlo learning\"\"\"\n",
    "    possible_moves={1,2,3,4,5,6,7,8,9} \n",
    "    available_moves= state.x.union(state.o)\n",
    "    available_moves=possible_moves.difference(available_moves)\n",
    "    next_moves=dict()\n",
    "    if len(available_moves)==0:\n",
    "        return -1\n",
    "    for move in available_moves:\n",
    "        next_move=deepcopy(state)\n",
    "        next_move.x.add(move)\n",
    "        hashable_move = (frozenset(next_move.x), frozenset(next_move.o))\n",
    "        next_moves[hashable_move]=value_dictionary[hashable_move]\n",
    "    \n",
    "    m= max(list(next_moves.items()), key=lambda e: e[1])\n",
    "    return State(set(m[0][0]),set(m[0][1]))\n",
    "    \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:27:41.412965Z",
     "start_time": "2023-12-24T16:27:41.145215100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X|O|.|\n",
      ".|O|X|\n",
      "O|X|.|\n"
     ]
    },
    {
     "data": {
      "text/plain": "State(x={1, 2, 3}, o={4, 5, 7})"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=State({1,2,3},{4,5,7})\n",
    "print_board(s)\n",
    "best=best_move(s)\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:27:47.652532300Z",
     "start_time": "2023-12-24T16:27:47.302584900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def random_move(state: State)-> State:\n",
    "    \"\"\"plays random move, it is always O\"\"\"\n",
    "    possible_moves={1,2,3,4,5,6,7,8,9} \n",
    "    available_moves= state.x.union(state.o)\n",
    "    available_moves=possible_moves.difference(available_moves)\n",
    "    new_state=deepcopy(state)\n",
    "    m = choice(list(available_moves))\n",
    "    new_state.o.add(m)\n",
    "    return new_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:22:17.891480800Z",
     "start_time": "2023-12-24T16:22:17.382563800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def available(state:State)-> bool:\n",
    "    possible_moves={1,2,3,4,5,6,7,8,9}\n",
    "    available =possible_moves.difference(state.x.union(state.o))\n",
    "    return False if len(available)==0 else True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:04:17.576529500Z",
     "start_time": "2023-12-24T16:04:17.282792400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def possible_moves(state:State)->set:\n",
    "    if win(state.x) or win(state.o):\n",
    "        return {}\n",
    "    possible_moves={1,2,3,4,5,6,7,8,9}\n",
    "    available =possible_moves.difference(state.x.union(state.o))\n",
    "    return available"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T11:13:21.080085800Z",
     "start_time": "2023-12-25T11:13:20.827009200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def best_random_game(printable=False)->int:\n",
    "    \"\"\"game between MonteCarlo and purerandom player\"\"\"\n",
    "    state=State(set(),set())\n",
    "    if printable:\n",
    "        print_board(state)\n",
    "    \n",
    "    while available(state):\n",
    "        state=best_move(state)\n",
    "        if printable:\n",
    "            print_board(state)\n",
    "        if win(state.x):\n",
    "            break\n",
    "        \n",
    "        if available(state):\n",
    "            state=random_move(state)\n",
    "            if printable:\n",
    "                print_board(state)\n",
    "            if win(state.o):\n",
    "                break\n",
    "    return int(win(state.x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:54:27.675074900Z",
     "start_time": "2023-12-24T16:54:26.853349400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random_game()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:54:31.036801100Z",
     "start_time": "2023-12-24T16:54:30.948479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51271a7825304537b79bd121cb193209"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "9907"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Results of Montecarlo vs purerandom player\"\"\"\n",
    "wins=0\n",
    "for _ in tqdm(range(10000)):\n",
    "    wins+=best_random_game()\n",
    "wins"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T16:55:37.293980500Z",
     "start_time": "2023-12-24T16:54:58.103481800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "class Qlearning():\n",
    "    q_table = {}\n",
    "    win_REWARD = 10\n",
    "    loss_REWARD = -10\n",
    "    def __init__(self, k = None, epsilon = 0.98, alfa = 1, gamma = 1) -> None:        \n",
    "        self.epsilon = epsilon                      # epsilon\n",
    "        self.alfa = alfa        # alpha\n",
    "        self.gamma = gamma      # gamma  \n",
    "        self.loss_REWARD=-10\n",
    "        self.win_REWARD=10\n",
    "        \n",
    "    def makeKey(self, state):\n",
    "        \"\"\"initializes Q Table\"\"\"\n",
    "        if win(state.x) or win(state.o) or len(list(possible_moves(state)))==0:\n",
    "            return\n",
    "        poss_moves =list(possible_moves(state))\n",
    "        an_action = list(possible_moves(state))[0]\n",
    "        #print(f\"poss moves: {poss_moves} an action: {an_action}\")\n",
    "        # creating a Q Table\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        if (hashable_state, an_action) not in self.q_table:\n",
    "            for i in poss_moves:\n",
    "                self.q_table[(hashable_state,i)] = np.random.uniform(0.0,0.01)\n",
    "    \n",
    "    def policy(self,state)->int:\n",
    "        \"\"\"returns next move for X\"\"\"\n",
    "        if win(state.x) or win(state.o) or len(list(possible_moves(state)))==0:\n",
    "            return -1\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        poss_moves = list(possible_moves(state))\n",
    "        if random() < self.epsilon:\n",
    "            # choose the action with the highest reward\n",
    "            q_values = [self.q_table[(hashable_state,i)] for i in poss_moves]\n",
    "            return poss_moves[np.argmax(q_values)]\n",
    "        else:\n",
    "            # choose a random action\n",
    "            return choice(poss_moves)\n",
    "    def max_val(self,state):\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        poss_moves = list(possible_moves(state))\n",
    "        q_values = [self.q_table[(hashable_state,i)] for i in poss_moves]\n",
    "        return poss_moves[np.argmax(q_values)]\n",
    "    def update_q(self,state, action, next_state, next_action):\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        hashable_next_state = (frozenset(next_state.x), frozenset(next_state.o))\n",
    "        reward=0\n",
    "        if win(next_state.x):\n",
    "            reward+=self.win_REWARD\n",
    "        elif win(next_state.o):\n",
    "            reward+=self.loss_REWARD\n",
    "        self.q_table[(hashable_state,action)]= (1-self.alfa)* self.q_table[(hashable_state,action)]+ self.alfa*(reward+ self.gamma* self.q_table[(hashable_next_state,next_action)])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:31:50.178400Z",
     "start_time": "2023-12-25T22:31:49.949499100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "def training(q,printable=False):\n",
    "    state=State(set(),set())\n",
    "    q.makeKey(state)\n",
    "    if printable:\n",
    "        print_board(state)\n",
    "    \n",
    "    while available(state):\n",
    "        action=q.policy(state)\n",
    "        prev_state=deepcopy(state)\n",
    "        state.x.add(action)\n",
    "        if printable:\n",
    "            print_board(state)\n",
    "        if win(state.x):\n",
    "            break\n",
    "        \n",
    "        if available(state):\n",
    "            state=random_move(state)\n",
    "            if printable:\n",
    "                print_board(state)\n",
    "            if win(state.o):\n",
    "                break\n",
    "        if available(state):            \n",
    "            q.makeKey(state)\n",
    "            q.update_q(prev_state,action, state,q.policy(state))\n",
    "    return int(win(state.x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:30:11.337336800Z",
     "start_time": "2023-12-25T22:30:11.060063200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8089a1278de44339cd9c9676709d3e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "6717"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Results of Qlearning vs pure random player\"\"\"\n",
    "wins=0\n",
    "q=Qlearning()\n",
    "for _ in tqdm(range(10000)):\n",
    "    wins+=training(q)\n",
    "wins"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-25T22:30:53.263325600Z",
     "start_time": "2023-12-25T22:30:30.308056200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
